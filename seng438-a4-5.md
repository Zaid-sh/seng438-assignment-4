**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 – Mutation Testing and Web app testing**

| Group: 5      |
|-----------------|
| Mohammed Zaid Shaikh   |
| Alexander Lai          |
| Odin Fox               |
| Aidan Gaede-Janke      |

# Introduction
This lab report tests the mutation coverage of the test suite made in assingment 3. Using the Pitest extention in eclipse, we could increase the mutation coverage of the tests to account for changes to the source code. This lab aslo includes GUI testing through selenium IDE where we tested a website with recordings of automated GUI tests.

Our goal was to modify our existing tests to increase mutation coverage and learn how to use selenium IDE.

# Analysis of 10 Mutants of the Range class
Looking at the mutants generated for lines 91 and 92, we can observe mutants that survive and
mutants that are killed.
<img src="media/Function.png" alt="media/Function.png"/>
<img src="media/Mutations.png" alt="media/Mutations.png"/>

Looking specifically at line 92, we can observe 11 mutants. The first three mutants that are killed each remove the append calls built into java StringBuilder (that take the form of the ‘+’s in line 92). Since removing an append call breaks the string initialization, the test catches the mutation, killing each one. Mutations 4-6 replace the aforementioned calls with a similar call to append with receiver, none of which are caught by the test case, and as such, they survive. Mutations 8-11 create mutations by incrementing the local variable number in the test, which is not relevant in line 92. Since it isn’t relevant, the increment does nothing, and goes undetected. As such, PiTest tells us that they survive, even though the mutations are inconsequential.

# Report all the statistics and the mutation score for each test class

(Before Mutation Test Cases)
(Range)
![image](https://github.com/user-attachments/assets/067d83ef-f9f5-48b2-a23d-945a966f2480)

(After Mutation Test Cases)
(Range)
![image](https://github.com/user-attachments/assets/ceb4ce11-edfc-4c69-89c0-73cf8d68324c)

Data Utilities Test

<img src="media/data utilities coverage.png" alt="media/data utilities coverage.png"/>

# Analysis drawn on the effectiveness of each of the test classes
Each of the test classes for Range and DataUtilities already had a very high mutation coverage, which made increasing the coverage much more difficult. DataUtilities couldn't be effectively increased, and Range was only able to be increased by 7% as there are alot of methods and conditions needed to be tested.

# A discussion on the effect of equivalent mutants on mutation score accuracy

Equivalent mutants are muatations that do not actually change the program behavior, for example returning a 2 instead of a 1 in a method that only returns a truth value (0 or 1). These mutants are unkillable, and can incorrectly skew the actual amount of mutants killed.

# A discussion of what could have been done to improve the mutation score of the test suites

The Datautilities test suite did not increase the mutation score because it had a 90% score from the beginning. This was close to the limit of mutation coverage because of equivalent mutants capping the possible coverage. The Range test suite coverage was simply increased via adding more test cases to allow for more possible mutants to be killed, as well as reversing asserts functions to check for opposite outputs. 

# Why do we need mutation testing? Advantages and disadvantages of mutation testing
Mutation testing, instead of testing the application in question, tests how good the test classes/suite for that application are. It's important to make sure that your test cases are up to board and can account for errors in the testing, there are disadvantages to it however. Mutation testing is not practical unless you implement an automation tool like PITEST in order to creatte the mutations, additionally its very time consuming to check for mutations. The advantages are substantial though, as it can help increase the quality of the SUT by weeding out weak tests and increase code coverage.

# Explain your SELENUIM test case design process
The test cases were designed by first considering the website's basic functionalities, such as adding/removing products from the cart, being able to sign in, and changing locations. After we discussed more intricate features that could be tested, we built on the basic functionalities, such as adding multiple quantities of one item into the cart, the search quality, and the coupon functionality. The test cases were created to ensure that they worked regardless of changes in the website, such as new trending products, not using the shortcuts for searching, etc.

# Explain the use of assertions and checkpoints
Assertions were used to detect if the selenium tests were functioning as expected through checking if the element displayed was correct, the correct button was clicked, etc. Confirming conditions like element presence, text correctness, or the correct URL helps ensure that a test case is operating as intended.  Depending on the type of assertion used, the test may either end or proceed if an assertion fails. Furthermore, the selenium test cases we developed utilized different types of assertions to validate the test cases.

# How did you test each functionaity with different test data
We had 8 test cases in our Selenium tests: Add multiple quantities to cart, add and remove, add an item to cart, change location, load coupons, login and logout, search item, and sign in. Most test cases were designed by simply navigating to the correct product and clicking add to cart. For example, for the add and remove test, we click a product, add it to the cart, navigate to the cart, and click to remove button. Other test cases require text input, such as the login and logout, which will use an already existing account to log in and then navigate to the logout button in the navigation menu. Many methods were used to accurately test the functionalities of the different test cases.

# Discuss advantages and disadvantages of Selenium vs. Sikulix
A popular automation tool, Selenium has a strong community, extensive documentation, and cross-browser compatibility.  It supports a number of programming languages, including Java, Python, and JavaScript, and saves time by automating tests. However,  It is restricted to webpages and occasionally has trouble recognizing features on responsive designs.

SikuliX, on the other hand, uses picture recognition for automation and can run on any GUI on Windows, Mac, and Linux.  Its language support is restricted to Python 2.7, Ruby, JavaScript, and certain Java-based languages, despite the fact that it provides versatility beyond online applications.  Furthermore, saved photos might match more than one element, which could lead to inconsistent test execution.

# How the team work/effort was divided and managed
Each member of the group automated the GUI testing of two features on the superstore website. The work to improve the mutation scores of our test suite was relatively light as our mutation score was already high, but we each took charge of test suites we developed in assignment 2.

# Difficulties encountered, challenges overcome, and lessons learned
The primary difficulty encountered was the setup of PiTest, which was resolved through repeating various steps of the setup until it eventually functioned as intended. The Pitest application was causing major difficulties as the Java version was not compatible with the Pitest programs, and only a specific Eclipse version would work for Pitest (2023-12). We overcame this by attempting to try different versions and installing the correct version for Eclipse. This allowed us to learn how to overcome difficulties in terms of version compatibility and was a good lesson on the importance of checking the compatibility before attempting to run an application.

# Comments/feedback on the lab itself

The lab was nice because it demonstrated how to use a method to automatically test GUI's which is more variable than normal code. It was challenging in the fact where you needed to figure out how to get more mutation coverage from tests that weren't initially designed for mutation testing. It was also difficult because sselenium was not available on chrome so edge or firefox had to be downloaded to make the GUI tests.
